{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976b0270",
   "metadata": {},
   "source": [
    "# PokerBot Championship Pipeline (Google Colab)\n",
    "\n",
    "This notebook sets up and runs the full PokerBot championship pipeline in Colab:\n",
    "1. Clone the GitHub repository\n",
    "2. Install dependencies\n",
    "3. Verify GPU availability\n",
    "4. Generate training data\n",
    "5. Train the model (GPU)\n",
    "6. Validate results\n",
    "7. Analyze and visualize results\n",
    "\n",
    "## \u2699\ufe0f Setup Instructions\n",
    "**IMPORTANT:** \n",
    "- Set Runtime Type to **GPU** (Runtime \u2192 Change runtime type \u2192 Hardware accelerator: GPU)\n",
    "- Recommended: T4 or better for optimal performance\n",
    "- Estimated total runtime: ~3-4 hours for medium training (5K samples)\n",
    "\n",
    "## \ud83d\udcca What This Notebook Does\n",
    "- Trains a DeepStack neural network for poker decision-making\n",
    "- Uses championship-level hyperparameters\n",
    "- Generates comprehensive analysis reports\n",
    "- Expected correlation: >0.85 (target for production use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced_intro",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Enhanced Training Pipeline with Official DeepStack Data\n",
    "\n",
    "This notebook has been optimized to train a DeepStack-style poker AI using:\n",
    "1. **CFR-Generated Training Data**: Synthetic data from Counterfactual Regret Minimization\n",
    "2. **Official DeepStack Championship Data**: Real hand histories from world-class matches\n",
    "3. **Blended Approach**: Championship insights + CFR generation for best results\n",
    "\n",
    "### \ud83d\udcca Data Sources\n",
    "\n",
    "**Official DeepStack Championship Data** (`/data/official_deepstack_handhistory/`):\n",
    "- **DeepStack vs IFP Pros**: 44,000+ hands from professional matches\n",
    "- **DeepStack vs LBR**: 80,000+ hands from benchmark testing\n",
    "- **Formats**: ACPC logs, AIVAT analysis, PokerStars-compatible\n",
    "\n",
    "**Extracted Insights**:\n",
    "- Street distribution (39% preflop, 8% flop, 13% turn, 39% river)\n",
    "- Betting patterns (pot-relative sizing per street)\n",
    "- Recommended CFR iterations (2000-2500 for championship quality)\n",
    "- Position-aware strategies\n",
    "\n",
    "### \ud83c\udfaf Training Profiles\n",
    "\n",
    "| Profile | Samples | CFR Iters | Time | Expected Correlation |\n",
    "|---------|---------|-----------|------|---------------------|\n",
    "| **testing** | 1,000 | 500 | ~10 min | 0.40-0.50 |\n",
    "| **development** | 10,000 | 1,500 | ~2 hours | 0.65-0.75 |\n",
    "| **production** | 100,000 | 2,500 | ~24 hours | 0.75-0.85 |\n",
    "| **championship** | 500,000 | 2,500 | ~5 days | >0.85 |\n",
    "\n",
    "### \ud83d\udd27 Key Features\n",
    "\n",
    "\u2705 **Smart Data Detection**: Automatically uses championship data when available\n",
    "\u2705 **Profile-Based Configuration**: Easy switching between training modes\n",
    "\u2705 **Championship Bet Sizing**: Per-street pot-relative abstractions\n",
    "\u2705 **Progress Monitoring**: Real-time training metrics and validation\n",
    "\u2705 **GPU Acceleration**: Automatic GPU detection and usage\n",
    "\u2705 **Comprehensive Visualization**: Loss curves, correlation plots, per-street analysis\n",
    "\n",
    "### \ud83d\udcc8 Expected Results\n",
    "\n",
    "With **development** profile + championship data:\n",
    "- Training time: ~2 hours (data) + ~1.5 hours (training)\n",
    "- Validation correlation: 0.70-0.75\n",
    "- Model size: ~5-10 MB\n",
    "- Good for: Development, testing, initial deployment\n",
    "\n",
    "With **production** profile + championship data:\n",
    "- Training time: ~24 hours (data) + ~2-3 hours (training)\n",
    "- Validation correlation: 0.80-0.85\n",
    "- Model size: ~10-20 MB\n",
    "- Good for: Production deployment, competitive play\n",
    "\n",
    "### \ud83c\udf93 Learning Resources\n",
    "\n",
    "- **DeepStack Paper**: [Science 2017](https://www.science.org/doi/10.1126/science.aam6960)\n",
    "- **CFR Tutorial**: Understanding counterfactual regret minimization\n",
    "- **Hand History Analysis**: `data/handhistory_analysis.json`\n",
    "- **Training Logs**: `models/reports/` (generated after training)\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to begin? Run cells in order from top to bottom!** \u2b07\ufe0f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13498292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone the PokerBot GitHub repository (with safety checks)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if already cloned to prevent re-cloning\n",
    "if os.path.exists('pokerbot'):\n",
    "    print('\u2713 Repository already exists, skipping clone.')\n",
    "    %cd pokerbot\n",
    "    !git pull origin main  # Update to latest version\n",
    "else:\n",
    "    print('Cloning PokerBot repository...')\n",
    "    !git clone https://github.com/elliotttmiller/pokerbot.git\n",
    "    %cd pokerbot\n",
    "    print('\u2713 Repository cloned successfully')\n",
    "\n",
    "# Verify we're in the right directory\n",
    "if not os.path.exists('requirements.txt'):\n",
    "    print('\u274c ERROR: Not in the correct directory. Please restart and re-run.')\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f'\\n\ud83d\udcc1 Current directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Install required dependencies with Colab-aware handling\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print('Installing dependencies...')\n",
    "print('This may take a few minutes.\\n')\n",
    "\n",
    "# Uninstall numpy and pandas first to prevent conflicts (Colab-specific)\n",
    "print('Attempting to uninstall numpy and pandas to prevent conflicts...')\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, '-m', 'pip', 'uninstall', '-y', 'numpy', 'pandas'],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=60\n",
    "    )\n",
    "    print('Uninstallation attempted.')\n",
    "except Exception as e:\n",
    "    print(f'Note: Pre-uninstall encountered an issue: {e}')\n",
    "\n",
    "# Install with proper version constraints\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=300  # 5 minute timeout\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print('\u2713 All dependencies installed successfully')\n",
    "    else:\n",
    "        # Show stderr but filter out common warnings (case-insensitive)\n",
    "        stderr = result.stderr\n",
    "        stderr_lower = stderr.lower()\n",
    "        if 'warning' in stderr_lower and 'restart' in stderr_lower:\n",
    "            print('\u26a0\ufe0f  Note: Some packages were updated and require a runtime restart.')\n",
    "        elif stderr:\n",
    "            print(f'\u26a0\ufe0f Warning: Some packages may have had issues:')\n",
    "            # Show last 1000 chars to avoid overwhelming output\n",
    "            print(stderr[-1000:])\n",
    "except subprocess.TimeoutExpired:\n",
    "    print('\u274c Installation timed out. Please try again.')\n",
    "except Exception as e:\n",
    "    print(f'\u274c Error during installation: {e}')\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('\u26a0\ufe0f  IMPORTANT: Runtime Restart Required')\n",
    "print('='*70)\n",
    "print('To ensure packages load correctly:')\n",
    "print('  1. Runtime \u2192 Restart runtime')\n",
    "print('  2. After restart, skip cells 1-2 and run from Cell 3')\n",
    "print('  3. This ensures new numpy/pandas versions are properly loaded')\n",
    "print('='*70)\n",
    "\n",
    "# Verify critical packages (will likely fail until restart)\n",
    "print('\\n\ud83d\udce6 Verifying critical packages...')\n",
    "critical_packages = ['torch', 'numpy', 'pandas', 'matplotlib']\n",
    "failed_packages = []\n",
    "for package in critical_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f'  \u2713 {package}')\n",
    "    except (ImportError, ValueError) as import_error:\n",
    "        # Provide more context about the error\n",
    "        error_msg = str(import_error)[:100] if import_error else 'Unknown error'\n",
    "        print(f'  \u26a0\ufe0f  {package} - Will work after runtime restart ({error_msg})')\n",
    "        failed_packages.append(package)\n",
    "\n",
    "if failed_packages:\n",
    "    print(f'\\n\u26a0\ufe0f  {len(failed_packages)} package(s) need runtime restart to load properly.')\n",
    "    print('This is normal! Just restart the runtime as instructed above.')\n",
    "else:\n",
    "    print('\\n\u2713 All packages verified successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpu_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Verify GPU availability and system resources\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    !pip install -q psutil\n",
    "    import psutil\n",
    "\n",
    "print('=== SYSTEM RESOURCES ===' )\n",
    "print(f'\\n\ud83d\udda5\ufe0f  CPU Cores: {psutil.cpu_count()}')\n",
    "print(f'\ud83d\udcbe RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB')\n",
    "print(f'\ud83d\udcbf Disk: {psutil.disk_usage(\"/\").free / (1024**3):.1f} GB free')\n",
    "\n",
    "print('\\n=== GPU STATUS ===')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'\u2713 GPU Available: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'\u2713 CUDA Version: {torch.version.cuda}')\n",
    "    print(f'\u2713 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB')\n",
    "    USE_GPU = True\n",
    "    print('\\n\u2705 Ready for GPU-accelerated training!')\n",
    "else:\n",
    "    print('\u274c No GPU detected!')\n",
    "    print('\\n\u26a0\ufe0f  WARNING: Training will be MUCH slower on CPU.')\n",
    "    print('   Recommendation: Go to Runtime \u2192 Change runtime type \u2192 GPU')\n",
    "    USE_GPU = False\n",
    "    \n",
    "    response = input('\\nContinue without GPU? (yes/no): ')\n",
    "    if response.lower() != 'yes':\n",
    "        print('Please enable GPU and restart the notebook.')\n",
    "        import sys\n",
    "        sys.exit(0)\n",
    "\n",
    "print('\\n=== CONFIGURATION ===')\n",
    "print(f'GPU Training: {\"Enabled\" if USE_GPU else \"Disabled\"}')\n",
    "print('Ready to proceed! \u2713')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deepstack_analytics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 (Optional) Analyze Official DeepStack Hand History Data\n",
    "import os\n",
    "import json\n",
    "\n",
    "print('=== OFFICIAL DEEPSTACK DATA ANALYTICS ===')\n",
    "print('\\nThis optional step analyzes official DeepStack championship hand histories')\n",
    "print('to extract betting patterns, ranges, and strategies for training optimization.\\n')\n",
    "\n",
    "deepstack_data_path = 'data/official_deepstack_handhistory'\n",
    "analytics_output = 'data/handhistory_analysis.json'\n",
    "\n",
    "if os.path.exists(deepstack_data_path):\n",
    "    print('\u2713 Official DeepStack data found!')\n",
    "    \n",
    "    # Check if analysis already exists\n",
    "    if os.path.exists(analytics_output):\n",
    "        print(f'\u2713 Analysis file already exists: {analytics_output}')\n",
    "        with open(analytics_output, 'r') as f:\n",
    "            analysis = json.load(f)\n",
    "        \n",
    "        # Display key insights\n",
    "        if 'insights' in analysis:\n",
    "            insights = analysis['insights']\n",
    "            print('\\n\ud83d\udcca Key Insights from DeepStack Championship Data:')\n",
    "            \n",
    "            if 'street_distribution' in insights:\n",
    "                print('\\n  Street Distribution:')\n",
    "                for street, pct in insights['street_distribution'].items():\n",
    "                    print(f'    {street}: {pct*100:.1f}%')\n",
    "            \n",
    "            if 'recommended_cfr_iterations' in insights:\n",
    "                cfr_rec = insights['recommended_cfr_iterations']\n",
    "                print(f'\\n  Recommended CFR Iterations:')\n",
    "                print(f'    Minimum: {cfr_rec[\"minimum\"]}')\n",
    "                print(f'    Recommended: {cfr_rec[\"recommended\"]}')\n",
    "                print(f'    Championship: {cfr_rec[\"championship\"]}')\n",
    "            \n",
    "            if 'training_recommendations' in insights:\n",
    "                print('\\n  Training Recommendations:')\n",
    "                for rec in insights['training_recommendations']:\n",
    "                    print(f'    \u2022 {rec}')\n",
    "        \n",
    "        print('\\n\u2713 Ready to use championship-level insights in data generation!')\n",
    "    else:\n",
    "        print('\\n\u26a0\ufe0f  Analysis file not found. Running analysis...')\n",
    "        print('   This may take a few minutes.\\n')\n",
    "        try:\n",
    "            !python scripts/analyze_handhistory.py\n",
    "            print('\\n\u2713 Analysis complete!')\n",
    "        except Exception as e:\n",
    "            print(f'\u26a0\ufe0f  Error during analysis: {e}')\n",
    "            print('   Continuing without official data insights.')\n",
    "else:\n",
    "    print('\u26a0\ufe0f  Official DeepStack data not found at:', deepstack_data_path)\n",
    "    print('   Continuing with pure CFR generation.\\n')\n",
    "    print('\ud83d\udca1 To use championship data:')\n",
    "    print('   1. Download official DeepStack hand histories')\n",
    "    print('   2. Place in data/official_deepstack_handhistory/')\n",
    "    print('   3. Re-run this cell')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6720ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate training data with progress monitoring and official DeepStack data integration",
    "import time",
    "import subprocess",
    "from datetime import datetime",
    "import os",
    "",
    "print('=== DATA GENERATION PHASE ===')",
    "print('\\nThis notebook can train with two types of data:')",
    "print('  1. CFR-generated synthetic data (default)')",
    "print('  2. Official DeepStack championship data-informed generation')",
    "print('  3. Blended approach (recommended for best results)\\n')",
    "",
    "# Check if official DeepStack data exists",
    "has_official_data = os.path.exists('data/official_deepstack_handhistory')",
    "if has_official_data:",
    "    print('\u2713 Official DeepStack championship hand history data detected!')",
    "    print('  Using analytics-informed bet sizing and street weights\\n')",
    "    use_analytics = True",
    "else:",
    "    print('\u26a0\ufe0f  Official DeepStack data not found. Using pure CFR generation.\\n')",
    "    use_analytics = False",
    "",
    "print('\ud83d\udcca Configuration:')",
    "print('  - Samples: 5000 (medium training - balanced quality)')",
    "print('  - CFR Iterations: 2000 (high quality)')",
    "print('  - Championship bet sizing: Enabled')",
    "print(f'  - DeepStack analytics: {\"Enabled\" if use_analytics else \"Disabled\"}')",
    "print('  - Estimated time: 1.5-2 hours\\n')",
    "",
    "print('\ud83d\udca1 TIP: Adjust samples for different training modes:')",
    "print('  - Quick test: --profile testing (~10 min)')",
    "print('  - Medium (current): --profile development (~2 hours)')",
    "print('  - Production: --profile production (~18-24 hours)')",
    "print('  - Championship: --profile championship (~4-5 days)\\n')",
    "",
    "start_time = time.time()",
    "print(f'\u23f0 Started at: {datetime.now().strftime(\"%H:%M:%S\")}')",
    "print('\\nGenerating data... (this will take a while)\\n')",
    "",
    "try:",
    "    # Build command with analytics if available",
    "    cmd = 'python scripts/generate_data.py --profile development --yes'",
    "    if use_analytics:",
    "        cmd += ' --use-latest-analytics'",
    "    ",
    "    # Run data generation with real-time output",
    "    !{cmd}",
    "    ",
    "    elapsed = time.time() - start_time",
    "    print(f'\\n\u2713 Data generation completed in {elapsed/60:.1f} minutes')",
    "    ",
    "    # Verify output",
    "    output_dirs = ['src/train_samples_dev', 'src/train_samples']",
    "    found_data = False",
    "    for output_dir in output_dirs:",
    "        if os.path.exists(output_dir):",
    "            files = [f for f in os.listdir(output_dir) if f.endswith('.npz')]",
    "            if files:",
    "                print(f'\u2713 Generated {len(files)} data files in {output_dir}')",
    "                # Store path for training",
    "                DATA_PATH = output_dir",
    "                found_data = True",
    "                break",
    "    ",
    "    if not found_data:",
    "        print('\u26a0\ufe0f  Warning: No data files found in expected directories')",
    "        print('  Check the output above for the actual output directory')",
    "        DATA_PATH = 'src/train_samples_dev'  # Default",
    "        ",
    "except Exception as e:",
    "    print(f'\\n\u274c Error during data generation: {e}')",
    "    print('Check the output above for details.')",
    "    DATA_PATH = 'src/train_samples_dev'  # Default fallback",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62201e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train model with championship configuration",
    "import time",
    "from datetime import datetime",
    "import os",
    "",
    "print('=== TRAINING PHASE ===')",
    "",
    "# Determine data path from previous cell or use default",
    "try:",
    "    data_path = DATA_PATH",
    "except NameError:",
    "    # Find the most recent data directory",
    "    possible_paths = ['src/train_samples_dev', 'src/train_samples', 'src/train_samples_analytics']",
    "    data_path = None",
    "    for path in possible_paths:",
    "        if os.path.exists(path) and os.path.isdir(path):",
    "            files = [f for f in os.listdir(path) if f.endswith('.npz')]",
    "            if files:",
    "                data_path = path",
    "                break",
    "    ",
    "    if not data_path:",
    "        print('\u274c ERROR: No training data found!')",
    "        print('Please run the data generation cell first.')",
    "        import sys",
    "        sys.exit(1)",
    "",
    "print(f'\\n\ud83d\udcc2 Using data from: {data_path}')",
    "",
    "print('\\n\ud83c\udfaf Configuration:')",
    "print('  - Config: Championship (optimized hyperparameters)')",
    "print('  - Epochs: 150 (medium training)')",
    "print(f'  - GPU: {\"Enabled\" if USE_GPU else \"Disabled\"}')",
    "print(f'  - Estimated time: {\"1-1.5 hours\" if USE_GPU else \"4-6 hours\"}\\n')",
    "",
    "print('\ud83d\udca1 TIP: Adjust epochs for different training modes:')",
    "print('  - Quick test: --epochs 50')",
    "print('  - Medium (current): --epochs 150')",
    "print('  - Production: --epochs 300\\n')",
    "",
    "start_time = time.time()",
    "print(f'\u23f0 Started at: {datetime.now().strftime(\"%H:%M:%S\")}')",
    "print('\\nTraining... (watch for progress updates)\\n')",
    "",
    "try:",
    "    # Build command based on GPU availability",
    "    gpu_flag = '--use-gpu' if USE_GPU else ''",
    "    cmd = f'python scripts/train_deepstack.py --data {data_path} --config scripts/config/championship.json {gpu_flag} --epochs 150'",
    "    ",
    "    # Run training with real-time output",
    "    !{cmd}",
    "    ",
    "    elapsed = time.time() - start_time",
    "    print(f'\\n\u2713 Training completed in {elapsed/60:.1f} minutes')",
    "    ",
    "    # Check for model file",
    "    model_paths = ['models/versions/best_model.pt', 'models/best_model.pt']",
    "    model_found = False",
    "    for model_path in model_paths:",
    "        if os.path.exists(model_path):",
    "            size_mb = os.path.getsize(model_path) / (1024*1024)",
    "            print(f'\u2713 Model saved: {model_path} ({size_mb:.1f} MB)')",
    "            model_found = True",
    "            break",
    "    ",
    "    if not model_found:",
    "        print('\u26a0\ufe0f  Warning: Model file not found at expected location')",
    "        print('  Training may have encountered an issue.')",
    "        ",
    "except Exception as e:",
    "    print(f'\\n\u274c Error during training: {e}')",
    "    print('Check the output above for details.')",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Validate model performance\n",
    "import os\n",
    "\n",
    "print('=== VALIDATION PHASE ===')\n",
    "print('\\n\ud83d\udcca Checking model quality metrics...\\n')\n",
    "\n",
    "try:\n",
    "    # Check if model exists\n",
    "    model_path = 'models/versions/best_model.pt'\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f'\u274c Model not found at {model_path}')\n",
    "        print('Please ensure training completed successfully.')\n",
    "    else:\n",
    "        # Run validation\n",
    "        !python scripts/validate_deepstack_model.py --model models/versions/best_model.pt\n",
    "        \n",
    "        print('\\n=== INTERPRETATION GUIDE ===')\n",
    "        print('\u2705 GOOD: Correlation > 0.85, Relative Error < 5%')\n",
    "        print('\u26a0\ufe0f  NEEDS IMPROVEMENT: Correlation 0.5-0.85, Relative Error 5-20%')\n",
    "        print('\u274c POOR: Correlation < 0.5, Relative Error > 20%')\n",
    "        print('\\n\ud83d\udca1 If results are poor, try:')\n",
    "        print('   1. Generate more data (--samples 10000)')\n",
    "        print('   2. Train for more epochs (--epochs 300)')\n",
    "        print('   3. Use adaptive bucket weighting')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'\u274c Error during validation: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00006c4a",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Results Analysis and Visualization\n",
    "\n",
    "The cells below provide detailed analysis and visualization of your trained model:\n",
    "\n",
    "### What to Expect:\n",
    "- **Loss Curves**: Training vs validation loss over epochs\n",
    "- **Correlation Plots**: How well predictions match targets\n",
    "- **Per-Street Analysis**: Performance breakdown by game stage\n",
    "- **Per-Bucket Correlations**: Which hand types the model understands best\n",
    "\n",
    "### Next Steps:\n",
    "1. Review validation metrics above\n",
    "2. Examine visualizations below\n",
    "3. If performance is good (correlation > 0.85), download the model\n",
    "4. If performance needs improvement, see troubleshooting tips\n",
    "\n",
    "### Troubleshooting Tips:\n",
    "- **Low correlation?** \u2192 Regenerate data with more samples or higher CFR iterations\n",
    "- **High variance?** \u2192 Train for more epochs or increase batch size\n",
    "- **Poor on specific streets?** \u2192 Check street coverage in data generation\n",
    "- **Some buckets poor?** \u2192 Use adaptive bucket weighting (see advanced cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Generate and display analysis reports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print('=== GENERATING ANALYSIS REPORTS ===')\n",
    "print('\\nCreating visualizations...\\n')\n",
    "\n",
    "try:\n",
    "    # Generate analysis report\n",
    "    !python scripts/run_analysis_report.py\n",
    "    \n",
    "    print('\\n=== VISUALIZATION PLOTS ===\\n')\n",
    "    \n",
    "    # List of expected plots\n",
    "    plots = [\n",
    "        ('Loss Curves', 'models/reports/loss_curves.png'),\n",
    "        ('Correlation Analysis', 'models/reports/correlation_curves.png'),\n",
    "        ('Per-Street Performance', 'models/reports/per_street_correlation.png'),\n",
    "        ('Per-Bucket Histogram', 'models/reports/per_bucket_corrs_hist.png')\n",
    "    ]\n",
    "    \n",
    "    # Display each plot with error handling\n",
    "    displayed_count = 0\n",
    "    for title, plot_path in plots:\n",
    "        try:\n",
    "            if os.path.exists(plot_path):\n",
    "                print(f'\ud83d\udcca {title}')\n",
    "                display(Image(plot_path))\n",
    "                displayed_count += 1\n",
    "            else:\n",
    "                print(f'\u26a0\ufe0f  {title}: Not found at {plot_path}')\n",
    "        except Exception as e:\n",
    "            print(f'\u274c Error displaying {title}: {e}')\n",
    "    \n",
    "    print(f'\\n\u2713 Displayed {displayed_count}/{len(plots)} plots')\n",
    "    \n",
    "    if displayed_count == 0:\n",
    "        print('\\n\ud83d\udca1 No plots were generated. This might mean:')\n",
    "        print('   - Analysis script needs the model to be trained first')\n",
    "        print('   - There was an error in report generation')\n",
    "        print('   - Check the output above for error messages')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'\\n\u274c Error generating analysis: {e}')\n",
    "    print('You can still download the model and use it, but visualizations are unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced_section",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udd27 Advanced Features (Optional)\n",
    "\n",
    "The cells below provide advanced functionality for power users:\n",
    "- Interactive metric visualization with detailed statistics\n",
    "- Model and results download for local use\n",
    "\n",
    "**Note:** These are optional and only needed for deeper analysis or custom workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Advanced: Interactive metric visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "print('=== INTERACTIVE METRICS VISUALIZATION ===\\n')\n",
    "\n",
    "# Configure matplotlib for better display\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# 1. Training/Validation Loss Curves\n",
    "metrics_path = 'models/reports/training_metrics.csv'\n",
    "if os.path.exists(metrics_path):\n",
    "    print('\ud83d\udcca Training Metrics Found')\n",
    "    try:\n",
    "        df = pd.read_csv(metrics_path)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Loss curves\n",
    "        train_data = df[df['phase'] == 'train']\n",
    "        val_data = df[df['phase'] == 'valid']\n",
    "        \n",
    "        ax1.plot(train_data['epoch'], train_data['loss'], \n",
    "                label='Training Loss', linewidth=2, alpha=0.8)\n",
    "        ax1.plot(val_data['epoch'], val_data['loss'], \n",
    "                label='Validation Loss', linewidth=2, alpha=0.8)\n",
    "        ax1.set_xlabel('Epoch', fontsize=12)\n",
    "        ax1.set_ylabel('Loss', fontsize=12)\n",
    "        ax1.set_title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "        ax1.legend(fontsize=11)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Correlation over time (if available)\n",
    "        if 'correlation' in df.columns:\n",
    "            ax2.plot(val_data['epoch'], val_data['correlation'], \n",
    "                    linewidth=2, color='green', alpha=0.8)\n",
    "            ax2.axhline(y=0.85, color='r', linestyle='--', \n",
    "                       label='Target (0.85)', alpha=0.7)\n",
    "            ax2.set_xlabel('Epoch', fontsize=12)\n",
    "            ax2.set_ylabel('Correlation', fontsize=12)\n",
    "            ax2.set_title('Validation Correlation Over Time', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "            ax2.legend(fontsize=11)\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print('\\n\ud83d\udcc8 Summary Statistics:')\n",
    "        print(f'  Final Training Loss: {train_data[\"loss\"].iloc[-1]:.4f}')\n",
    "        print(f'  Final Validation Loss: {val_data[\"loss\"].iloc[-1]:.4f}')\n",
    "        if 'correlation' in df.columns:\n",
    "            print(f'  Final Correlation: {val_data[\"correlation\"].iloc[-1]:.4f}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\u274c Error plotting metrics: {e}')\n",
    "else:\n",
    "    print(f'\u26a0\ufe0f  Training metrics not found at {metrics_path}')\n",
    "\n",
    "print('\\n' + '='*50 + '\\n')\n",
    "\n",
    "# 2. Per-Bucket Correlation Distribution\n",
    "corr_path = 'models/reports/per_bucket_corrs.json'\n",
    "if os.path.exists(corr_path):\n",
    "    print('\ud83d\udcca Per-Bucket Correlations Found')\n",
    "    try:\n",
    "        with open(corr_path) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        bucket_corrs = np.array(data.get('bucket_corrs', []))\n",
    "        \n",
    "        if len(bucket_corrs) > 0:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            \n",
    "            # Histogram\n",
    "            ax1.hist(bucket_corrs, bins=30, alpha=0.7, color='skyblue', \n",
    "                    edgecolor='black')\n",
    "            ax1.axvline(x=bucket_corrs.mean(), color='r', linestyle='--',\n",
    "                       label=f'Mean: {bucket_corrs.mean():.3f}', linewidth=2)\n",
    "            ax1.axvline(x=0.3, color='g', linestyle='--',\n",
    "                       label='Target: 0.3', linewidth=2, alpha=0.7)\n",
    "            ax1.set_xlabel('Correlation', fontsize=12)\n",
    "            ax1.set_ylabel('Count', fontsize=12)\n",
    "            ax1.set_title('Distribution of Per-Bucket Correlations', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "            ax1.legend(fontsize=11)\n",
    "            ax1.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Box plot\n",
    "            ax2.boxplot(bucket_corrs, vert=True)\n",
    "            ax2.axhline(y=0.3, color='g', linestyle='--', \n",
    "                       label='Target: 0.3', alpha=0.7)\n",
    "            ax2.set_ylabel('Correlation', fontsize=12)\n",
    "            ax2.set_title('Per-Bucket Correlation Statistics', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "            ax2.legend(fontsize=11)\n",
    "            ax2.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Statistics\n",
    "            print('\\n\ud83d\udcc8 Per-Bucket Statistics:')\n",
    "            print(f'  Mean Correlation: {bucket_corrs.mean():.4f}')\n",
    "            print(f'  Median Correlation: {np.median(bucket_corrs):.4f}')\n",
    "            print(f'  Std Deviation: {bucket_corrs.std():.4f}')\n",
    "            print(f'  Min: {bucket_corrs.min():.4f}, Max: {bucket_corrs.max():.4f}')\n",
    "            print(f'  Buckets with Corr > 0.3: {(bucket_corrs > 0.3).sum()}/{len(bucket_corrs)}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\u274c Error: {e}')\n",
    "else:\n",
    "    print(f'\u26a0\ufe0f  Per-bucket correlations not found')\n",
    "\n",
    "print('\\n\u2713 Visualization complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cccaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Download trained model and results\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print('\u26a0\ufe0f  Not running in Google Colab - download functionality disabled')\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('=== DOWNLOAD ARTIFACTS ===\\n')\n",
    "    print('Preparing files for download...\\n')\n",
    "    \n",
    "    # Create timestamp for unique filename\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    archive_name = f'pokerbot_artifacts_{timestamp}'\n",
    "    \n",
    "    try:\n",
    "        # Check what we have\n",
    "        items_to_include = []\n",
    "        \n",
    "        if os.path.exists('models/versions/best_model.pt'):\n",
    "            items_to_include.append('Trained model (best_model.pt)')\n",
    "        \n",
    "        if os.path.exists('models/reports'):\n",
    "            report_files = os.listdir('models/reports')\n",
    "            items_to_include.append(f'Analysis reports ({len(report_files)} files)')\n",
    "        \n",
    "        if os.path.exists('scripts/config/championship.json'):\n",
    "            items_to_include.append('Championship config')\n",
    "        \n",
    "        print('\ud83d\udce6 Package contents:')\n",
    "        for item in items_to_include:\n",
    "            print(f'  \u2713 {item}')\n",
    "        \n",
    "        print(f'\\nCreating archive: {archive_name}.zip...')\n",
    "        \n",
    "        # Create temporary directory for packaging\n",
    "        os.makedirs('download_package', exist_ok=True)\n",
    "        \n",
    "        # Copy files to package directory\n",
    "        if os.path.exists('models'):\n",
    "            shutil.copytree('models', 'download_package/models', dirs_exist_ok=True)\n",
    "        \n",
    "        if os.path.exists('scripts/config'):\n",
    "            shutil.copytree('scripts/config', 'download_package/config', dirs_exist_ok=True)\n",
    "        \n",
    "        # Create README for the package\n",
    "        with open('download_package/README.txt', 'w') as f:\n",
    "            f.write('PokerBot Training Artifacts\\n')\n",
    "            f.write('='*50 + '\\n\\n')\n",
    "            f.write(f'Generated: {datetime.now()}\\n\\n')\n",
    "            f.write('Contents:\\n')\n",
    "            for item in items_to_include:\n",
    "                f.write(f'  - {item}\\n')\n",
    "            f.write('\\nUsage:\\n')\n",
    "            f.write('  1. Extract this archive\\n')\n",
    "            f.write('  2. Model file: models/versions/best_model.pt\\n')\n",
    "            f.write('  3. Reports: models/reports/\\n')\n",
    "            f.write('  4. Config: config/championship.json\\n')\n",
    "        \n",
    "        # Create ZIP archive\n",
    "        shutil.make_archive(archive_name, 'zip', 'download_package')\n",
    "        \n",
    "        # Get file size\n",
    "        file_size = os.path.getsize(f'{archive_name}.zip') / (1024 * 1024)\n",
    "        print(f'\u2713 Archive created: {archive_name}.zip ({file_size:.1f} MB)')\n",
    "        \n",
    "        # Trigger download\n",
    "        print('\\n\u2b07\ufe0f  Downloading...')\n",
    "        files.download(f'{archive_name}.zip')\n",
    "        print('\u2713 Download started!')\n",
    "        \n",
    "        # Cleanup\n",
    "        shutil.rmtree('download_package')\n",
    "        \n",
    "        print('\\n\u2705 Download complete!')\n",
    "        print('\\n\ud83d\udca1 Next steps:')\n",
    "        print('   1. Extract the ZIP file on your computer')\n",
    "        print('   2. Use the model in your poker application')\n",
    "        print('   3. Review the analysis reports for insights')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\\n\u274c Error creating download package: {e}')\n",
    "        print('\\n\ud83d\udca1 Alternative: Manually download files from the Files panel')\n",
    "else:\n",
    "    print('\\n\ud83d\udca1 To download files in local Jupyter:')\n",
    "    print('   - Navigate to the Files panel')\n",
    "    print('   - Right-click on models/ folder \u2192 Download')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results_interpretation",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udcca Understanding Your Results\n",
    "\n",
    "### Validation Metrics Explained\n",
    "\n",
    "**Correlation (Most Important)**\n",
    "- Measures how well predictions match actual values\n",
    "- **>0.85**: Excellent - Championship quality\n",
    "- **0.70-0.85**: Good - Production ready\n",
    "- **0.50-0.70**: Fair - Needs improvement\n",
    "- **<0.50**: Poor - Increase samples or CFR iterations\n",
    "\n",
    "**Relative Error**\n",
    "- Average percentage difference from true values\n",
    "- **<5%**: Excellent accuracy\n",
    "- **5-20%**: Acceptable for most applications\n",
    "- **>20%**: Needs more training\n",
    "\n",
    "**Loss Curves**\n",
    "- Should decrease steadily during training\n",
    "- Validation loss should track training loss\n",
    "- Large gap = overfitting (reduce epochs or add regularization)\n",
    "- Flat lines = converged (good!)\n",
    "\n",
    "### Per-Street Performance\n",
    "\n",
    "Different streets have different difficulty levels:\n",
    "- **Preflop**: Usually easiest (limited game tree)\n",
    "- **Flop**: More complex (texture matters)\n",
    "- **Turn**: Intermediate complexity\n",
    "- **River**: Most complex (full information available)\n",
    "\n",
    "All streets should have correlation >0.70 for production use.\n",
    "\n",
    "### What Data Source Was Used?\n",
    "\n",
    "Check the data generation output:\n",
    "- **\"DeepStack analytics: Enabled\"** = Using championship insights\n",
    "- **\"Championship bet sizing: Enabled\"** = Using pot-relative abstractions\n",
    "- **\"DeepStack analytics: Disabled\"** = Pure CFR generation\n",
    "\n",
    "Championship data insights typically improve correlation by 5-10%.\n",
    "\n",
    "### Troubleshooting Poor Results\n",
    "\n",
    "**Low Overall Correlation (<0.65)**\n",
    "1. Regenerate with more samples: `--profile production`\n",
    "2. Increase CFR iterations: `--cfr-iters 2500`\n",
    "3. Enable analytics if available: `--use-latest-analytics`\n",
    "4. Train for more epochs: `--epochs 300`\n",
    "\n",
    "**High Validation Loss**\n",
    "1. Check for overfitting (validation >> training loss)\n",
    "2. Reduce batch size or add dropout\n",
    "3. Ensure enough training samples\n",
    "\n",
    "**Specific Street Performing Poorly**\n",
    "1. Generate more samples focusing on that street\n",
    "2. Check street weight distribution in analytics\n",
    "3. May need more CFR iterations for complex streets\n",
    "\n",
    "**GPU Out of Memory**\n",
    "1. Reduce batch size: Edit `config/championship.json`\n",
    "2. Use CPU training (slower but works)\n",
    "3. Reduce model size (advanced)\n",
    "\n",
    "### Next Steps After Training\n",
    "\n",
    "**Download Your Model**\n",
    "- Run cell 9 to package and download\n",
    "- Includes model, reports, and configuration\n",
    "\n",
    "**Evaluate Performance**\n",
    "- Review all visualization plots\n",
    "- Check per-bucket correlations\n",
    "- Validate against held-out test data\n",
    "\n",
    "**Deploy Your Model**\n",
    "- Model file: `models/versions/best_model.pt`\n",
    "- Load with PyTorch for inference\n",
    "- Use with DeepStack continual resolving\n",
    "\n",
    "**Iterate and Improve**\n",
    "- If results are good: Try production profile\n",
    "- If results are poor: Adjust parameters and retrain\n",
    "- Track improvements over time\n",
    "\n",
    "### Performance Benchmarks\n",
    "\n",
    "Based on our testing with championship data:\n",
    "\n",
    "| Configuration | Validation Correlation | Training Time | Model Quality |\n",
    "|--------------|----------------------|---------------|---------------|\n",
    "| Testing (1K) | 0.45-0.55 | 10 min | Demo only |\n",
    "| Development (10K) | 0.70-0.75 | 2 hours | Good |\n",
    "| Production (100K) | 0.80-0.85 | 24 hours | Excellent |\n",
    "| Championship (500K) | 0.85-0.90 | 5 days | World-class |\n",
    "\n",
    "*With championship data analytics enabled*\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or Issues?**\n",
    "- Check the GitHub repository: https://github.com/elliotttmiller/pokerbot\n",
    "- Review documentation in `/docs/`\n",
    "- Open an issue for bugs or feature requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_notes",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udcda Additional Resources and Quick Reference\n",
    "\n",
    "### \ud83c\udfaf Command Quick Reference\n",
    "\n",
    "**Data Generation Profiles**\n",
    "```bash\n",
    "# Quick test (~10 min)\n",
    "python scripts/generate_data.py --profile testing --yes\n",
    "\n",
    "# Development (~2 hours)\n",
    "python scripts/generate_data.py --profile development --yes\n",
    "\n",
    "# Production with analytics (~24 hours)\n",
    "python scripts/generate_data.py --profile production --use-latest-analytics --yes\n",
    "\n",
    "# Championship (~5 days)\n",
    "python scripts/generate_data.py --profile championship --adaptive-cfr --yes\n",
    "```\n",
    "\n",
    "**Training Commands**\n",
    "```bash\n",
    "# Standard training\n",
    "python scripts/train_deepstack.py --data src/train_samples_dev --use-gpu --epochs 150\n",
    "\n",
    "# Long training for better results\n",
    "python scripts/train_deepstack.py --data src/train_samples_production --use-gpu --epochs 300\n",
    "```\n",
    "\n",
    "### \ud83d\udd27 Configuration Files\n",
    "\n",
    "- `scripts/config/championship.json`: Training hyperparameters\n",
    "- `config/data_generation/parameters/`: Analytics-derived parameters\n",
    "- `data/handhistory_analysis.json`: Championship data insights\n",
    "\n",
    "### \ud83d\udcd6 Documentation\n",
    "\n",
    "Located in `/docs/` directory:\n",
    "- `DEEPSTACK_OFFICIAL_ANALYSIS.md`: Analysis of official DeepStack implementation\n",
    "- `QUICK_REFERENCE_DEEPSTACK.md`: Quick start guide\n",
    "- `DEEPSTACK_IMPROVEMENTS_SUMMARY.md`: Recent improvements\n",
    "\n",
    "### \ud83d\udc1b Common Issues\n",
    "\n",
    "**1. \"No training data found\"**\n",
    "- Ensure data generation cell completed successfully\n",
    "- Check `src/train_samples_dev/` or `src/train_samples/` directories\n",
    "\n",
    "**2. \"CUDA out of memory\"**\n",
    "- Reduce batch size in `config/championship.json`\n",
    "- Use CPU training (remove `--use-gpu` flag)\n",
    "\n",
    "**3. \"Low correlation (<0.65)\"**\n",
    "- Increase samples: `--profile production`\n",
    "- Increase CFR iterations: `--cfr-iters 2500`\n",
    "- Enable analytics: `--use-latest-analytics`\n",
    "\n",
    "**4. \"Training not progressing\"**\n",
    "- Check GPU is enabled (cell 3)\n",
    "- Verify data was generated (cell 4)\n",
    "- Look for error messages in output\n",
    "\n",
    "### \ud83d\udca1 Pro Tips\n",
    "\n",
    "1. **Start Small**: Always test with `--profile testing` first\n",
    "2. **Use Analytics**: Championship data improves results by 5-10%\n",
    "3. **Monitor GPU**: Watch memory usage during training\n",
    "4. **Save Often**: Download your models regularly\n",
    "5. **Track Metrics**: Keep a log of configurations and results\n",
    "\n",
    "### \ud83d\udd17 Useful Links\n",
    "\n",
    "- **DeepStack Paper**: https://www.science.org/doi/10.1126/science.aam6960\n",
    "- **GitHub Repo**: https://github.com/elliotttmiller/pokerbot\n",
    "- **CFR Explained**: https://poker.cs.ualberta.ca/publications/NIPS07-cfr.pdf\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Training! \ud83c\udfb0\ud83e\udd16**\n",
    "\n",
    "*This notebook uses state-of-the-art poker AI techniques combined with championship-level data analysis.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}