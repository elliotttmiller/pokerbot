{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976b0270",
   "metadata": {},
   "source": [
    "# PokerBot Championship Pipeline (Google Colab)\n",
    "\n",
    "This notebook sets up and runs the full PokerBot championship pipeline in Colab:\n",
    "1. Clone the GitHub repository\n",
    "2. Install dependencies\n",
    "3. Verify GPU availability\n",
    "4. Generate training data\n",
    "5. Train the model (GPU)\n",
    "6. Validate results\n",
    "7. Analyze and visualize results\n",
    "\n",
    "## \u2699\ufe0f Setup Instructions\n",
    "**IMPORTANT:** \n",
    "- Set Runtime Type to **GPU** (Runtime \u2192 Change runtime type \u2192 Hardware accelerator: GPU)\n",
    "- Recommended: T4 or better for optimal performance\n",
    "- Estimated total runtime: ~1-2 hours for quick training (1K samples)\n",
    "\n",
    "## \ud83d\udcca What This Notebook Does\n",
    "- Trains a DeepStack neural network for poker decision-making\n",
    "- Uses championship-level hyperparameters\n",
    "- Generates comprehensive analysis reports\n",
    "- Expected correlation: >0.85 (target for production use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13498292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone the PokerBot GitHub repository (with safety checks)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if already cloned to prevent re-cloning\n",
    "if os.path.exists('pokerbot'):\n",
    "    print('\u2713 Repository already exists, skipping clone.')\n",
    "    %cd pokerbot\n",
    "    !git pull origin main  # Update to latest version\n",
    "else:\n",
    "    print('Cloning PokerBot repository...')\n",
    "    !git clone https://github.com/elliotttmiller/pokerbot.git\n",
    "    %cd pokerbot\n",
    "    print('\u2713 Repository cloned successfully')\n",
    "\n",
    "# Verify we're in the right directory\n",
    "if not os.path.exists('requirements.txt'):\n",
    "    print('\u274c ERROR: Not in the correct directory. Please restart and re-run.')\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f'\\n\ud83d\udcc1 Current directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Install required dependencies with progress tracking\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print('Installing dependencies...')\n",
    "print('This may take 2-3 minutes.\\n')\n",
    "\n",
    "# Install with progress\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'pip', 'install', '-q', '-r', 'requirements.txt'],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=300  # 5 minute timeout\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print('\u2713 All dependencies installed successfully')\n",
    "    else:\n",
    "        print(f'\u26a0\ufe0f Warning: Some packages may have had issues:')\n",
    "        print(result.stderr)\n",
    "except subprocess.TimeoutExpired:\n",
    "    print('\u274c Installation timed out. Please try again.')\n",
    "except Exception as e:\n",
    "    print(f'\u274c Error during installation: {e}')\n",
    "\n",
    "# Verify critical packages\n",
    "print('\\n\ud83d\udce6 Verifying critical packages...')\n",
    "critical_packages = ['torch', 'numpy', 'pandas', 'matplotlib']\n",
    "for package in critical_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f'  \u2713 {package}')\n",
    "    except ImportError:\n",
    "        print(f'  \u274c {package} - MISSING!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpu_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Verify GPU availability and system resources\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    !pip install -q psutil\n",
    "    import psutil\n",
    "\n",
    "print('=== SYSTEM RESOURCES ===' )\n",
    "print(f'\\n\ud83d\udda5\ufe0f  CPU Cores: {psutil.cpu_count()}')\n",
    "print(f'\ud83d\udcbe RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB')\n",
    "print(f'\ud83d\udcbf Disk: {psutil.disk_usage(\"/\").free / (1024**3):.1f} GB free')\n",
    "\n",
    "print('\\n=== GPU STATUS ===')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'\u2713 GPU Available: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'\u2713 CUDA Version: {torch.version.cuda}')\n",
    "    print(f'\u2713 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB')\n",
    "    USE_GPU = True\n",
    "    print('\\n\u2705 Ready for GPU-accelerated training!')\n",
    "else:\n",
    "    print('\u274c No GPU detected!')\n",
    "    print('\\n\u26a0\ufe0f  WARNING: Training will be MUCH slower on CPU.')\n",
    "    print('   Recommendation: Go to Runtime \u2192 Change runtime type \u2192 GPU')\n",
    "    USE_GPU = False\n",
    "    \n",
    "    response = input('\\nContinue without GPU? (yes/no): ')\n",
    "    if response.lower() != 'yes':\n",
    "        print('Please enable GPU and restart the notebook.')\n",
    "        import sys\n",
    "        sys.exit(0)\n",
    "\n",
    "print('\\n=== CONFIGURATION ===')\n",
    "print(f'GPU Training: {\"Enabled\" if USE_GPU else \"Disabled\"}')\n",
    "print('Ready to proceed! \u2713')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6720ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate training data with progress monitoring\n",
    "import time\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "print('=== DATA GENERATION PHASE ===')\n",
    "print('\\n\ud83d\udcca Configuration:')\n",
    "print('  - Samples: 1000 (quick training)')\n",
    "print('  - CFR Iterations: 2000 (high quality)')\n",
    "print('  - Estimated time: 15-20 minutes\\n')\n",
    "\n",
    "print('\ud83d\udca1 TIP: For production use, increase to --samples 50000')\n",
    "print('         (will take ~10 hours but give much better results)\\n')\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'\u23f0 Started at: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "print('\\nGenerating data... (this will take a while)\\n')\n",
    "\n",
    "try:\n",
    "    # Run data generation with real-time output\n",
    "    !python scripts/generate_quick_data.py --samples 1000 --cfr-iters 2000\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f'\\n\u2713 Data generation completed in {elapsed/60:.1f} minutes')\n",
    "    \n",
    "    # Verify output\n",
    "    import os\n",
    "    if os.path.exists('src/train_samples'):\n",
    "        files = os.listdir('src/train_samples')\n",
    "        print(f'\u2713 Generated {len(files)} data files')\n",
    "    else:\n",
    "        print('\u26a0\ufe0f  Warning: Output directory not found')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'\\n\u274c Error during data generation: {e}')\n",
    "    print('Check the output above for details.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62201e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train model with championship configuration\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print('=== TRAINING PHASE ===')\n",
    "print('\\n\ud83c\udfaf Configuration:')\n",
    "print('  - Config: Championship (optimized hyperparameters)')\n",
    "print('  - Epochs: 200')\n",
    "print(f'  - GPU: {\"Enabled\" if USE_GPU else \"Disabled\"}')\n",
    "print(f'  - Estimated time: {\"30-40 minutes\" if USE_GPU else \"3-4 hours\"}\\n')\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'\u23f0 Started at: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "print('\\nTraining... (watch for progress updates)\\n')\n",
    "\n",
    "try:\n",
    "    # Build command based on GPU availability\n",
    "    gpu_flag = '--use-gpu' if USE_GPU else ''\n",
    "    cmd = f'python scripts/train_deepstack.py --config scripts/config/championship.json {gpu_flag} --epochs 200'\n",
    "    \n",
    "    # Run training with real-time output\n",
    "    !{cmd}\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f'\\n\u2713 Training completed in {elapsed/60:.1f} minutes')\n",
    "    \n",
    "    # Check for model file\n",
    "    import os\n",
    "    if os.path.exists('models/versions/best_model.pt'):\n",
    "        size_mb = os.path.getsize('models/versions/best_model.pt') / (1024*1024)\n",
    "        print(f'\u2713 Model saved: best_model.pt ({size_mb:.1f} MB)')\n",
    "    else:\n",
    "        print('\u26a0\ufe0f  Warning: Model file not found at expected location')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'\\n\u274c Error during training: {e}')\n",
    "    print('Check the output above for details.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Validate model performance\n",
    "import os\n",
    "\n",
    "print('=== VALIDATION PHASE ===')\n",
    "print('\\n\ud83d\udcca Checking model quality metrics...\\n')\n",
    "\n",
    "try:\n",
    "    # Check if model exists\n",
    "    model_path = 'models/versions/best_model.pt'\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f'\u274c Model not found at {model_path}')\n",
    "        print('Please ensure training completed successfully.')\n",
    "    else:\n",
    "        # Run validation\n",
    "        !python scripts/validate_deepstack_model.py --model models/versions/best_model.pt\n",
    "        \n",
    "        print('\\n=== INTERPRETATION GUIDE ===')\n",
    "        print('\u2705 GOOD: Correlation > 0.85, Relative Error < 5%')\n",
    "        print('\u26a0\ufe0f  NEEDS IMPROVEMENT: Correlation 0.5-0.85, Relative Error 5-20%')\n",
    "        print('\u274c POOR: Correlation < 0.5, Relative Error > 20%')\n",
    "        print('\\n\ud83d\udca1 If results are poor, try:')\n",
    "        print('   1. Generate more data (--samples 10000)')\n",
    "        print('   2. Train for more epochs (--epochs 300)')\n",
    "        print('   3. Use adaptive bucket weighting')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'\u274c Error during validation: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00006c4a",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Results Analysis and Visualization\n",
    "\n",
    "The cells below provide detailed analysis and visualization of your trained model:\n",
    "\n",
    "### What to Expect:\n",
    "- **Loss Curves**: Training vs validation loss over epochs\n",
    "- **Correlation Plots**: How well predictions match targets\n",
    "- **Per-Street Analysis**: Performance breakdown by game stage\n",
    "- **Per-Bucket Correlations**: Which hand types the model understands best\n",
    "\n",
    "### Next Steps:\n",
    "1. Review validation metrics above\n",
    "2. Examine visualizations below\n",
    "3. If performance is good (correlation > 0.85), download the model\n",
    "4. If performance needs improvement, see troubleshooting tips\n",
    "\n",
    "### Troubleshooting Tips:\n",
    "- **Low correlation?** \u2192 Regenerate data with more samples or higher CFR iterations\n",
    "- **High variance?** \u2192 Train for more epochs or increase batch size\n",
    "- **Poor on specific streets?** \u2192 Check street coverage in data generation\n",
    "- **Some buckets poor?** \u2192 Use adaptive bucket weighting (see advanced cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Generate and display analysis reports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print('=== GENERATING ANALYSIS REPORTS ===')\n",
    "print('\\nCreating visualizations...\\n')\n",
    "\n",
    "try:\n",
    "    # Generate analysis report\n",
    "    !python scripts/run_analysis_report.py\n",
    "    \n",
    "    print('\\n=== VISUALIZATION PLOTS ===\\n')\n",
    "    \n",
    "    # List of expected plots\n",
    "    plots = [\n",
    "        ('Loss Curves', 'models/reports/loss_curves.png'),\n",
    "        ('Correlation Analysis', 'models/reports/correlation_curves.png'),\n",
    "        ('Per-Street Performance', 'models/reports/per_street_correlation.png'),\n",
    "        ('Per-Bucket Histogram', 'models/reports/per_bucket_corrs_hist.png')\n",
    "    ]\n",
    "    \n",
    "    # Display each plot with error handling\n",
    "    displayed_count = 0\n",
    "    for title, plot_path in plots:\n",
    "        try:\n",
    "            if os.path.exists(plot_path):\n",
    "                print(f'\ud83d\udcca {title}')\n",
    "                display(Image(plot_path))\n",
    "                displayed_count += 1\n",
    "            else:\n",
    "                print(f'\u26a0\ufe0f  {title}: Not found at {plot_path}')\n",
    "        except Exception as e:\n",
    "            print(f'\u274c Error displaying {title}: {e}')\n",
    "    \n",
    "    print(f'\\n\u2713 Displayed {displayed_count}/{len(plots)} plots')\n",
    "    \n",
    "    if displayed_count == 0:\n",
    "        print('\\n\ud83d\udca1 No plots were generated. This might mean:')\n",
    "        print('   - Analysis script needs the model to be trained first')\n",
    "        print('   - There was an error in report generation')\n",
    "        print('   - Check the output above for error messages')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'\\n\u274c Error generating analysis: {e}')\n",
    "    print('You can still download the model and use it, but visualizations are unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced_section",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udd27 Advanced Features (Optional)\n",
    "\n",
    "The cells below provide advanced functionality for power users:\n",
    "- Interactive metric visualization with detailed statistics\n",
    "- Model and results download for local use\n",
    "\n",
    "**Note:** These are optional and only needed for deeper analysis or custom workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Advanced: Interactive metric visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "print('=== INTERACTIVE METRICS VISUALIZATION ===\\n')\n",
    "\n",
    "# Configure matplotlib for better display\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# 1. Training/Validation Loss Curves\n",
    "metrics_path = 'models/reports/training_metrics.csv'\n",
    "if os.path.exists(metrics_path):\n",
    "    print('\ud83d\udcca Training Metrics Found')\n",
    "    try:\n",
    "        df = pd.read_csv(metrics_path)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Loss curves\n",
    "        train_data = df[df['phase'] == 'train']\n",
    "        val_data = df[df['phase'] == 'valid']\n",
    "        \n",
    "        ax1.plot(train_data['epoch'], train_data['loss'], \n",
    "                label='Training Loss', linewidth=2, alpha=0.8)\n",
    "        ax1.plot(val_data['epoch'], val_data['loss'], \n",
    "                label='Validation Loss', linewidth=2, alpha=0.8)\n",
    "        ax1.set_xlabel('Epoch', fontsize=12)\n",
    "        ax1.set_ylabel('Loss', fontsize=12)\n",
    "        ax1.set_title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "        ax1.legend(fontsize=11)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Correlation over time (if available)\n",
    "        if 'correlation' in df.columns:\n",
    "            ax2.plot(val_data['epoch'], val_data['correlation'], \n",
    "                    linewidth=2, color='green', alpha=0.8)\n",
    "            ax2.axhline(y=0.85, color='r', linestyle='--', \n",
    "                       label='Target (0.85)', alpha=0.7)\n",
    "            ax2.set_xlabel('Epoch', fontsize=12)\n",
    "            ax2.set_ylabel('Correlation', fontsize=12)\n",
    "            ax2.set_title('Validation Correlation Over Time', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "            ax2.legend(fontsize=11)\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print('\\n\ud83d\udcc8 Summary Statistics:')\n",
    "        print(f'  Final Training Loss: {train_data[\"loss\"].iloc[-1]:.4f}')\n",
    "        print(f'  Final Validation Loss: {val_data[\"loss\"].iloc[-1]:.4f}')\n",
    "        if 'correlation' in df.columns:\n",
    "            print(f'  Final Correlation: {val_data[\"correlation\"].iloc[-1]:.4f}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\u274c Error plotting metrics: {e}')\n",
    "else:\n",
    "    print(f'\u26a0\ufe0f  Training metrics not found at {metrics_path}')\n",
    "\n",
    "print('\\n' + '='*50 + '\\n')\n",
    "\n",
    "# 2. Per-Bucket Correlation Distribution\n",
    "corr_path = 'models/reports/per_bucket_corrs.json'\n",
    "if os.path.exists(corr_path):\n",
    "    print('\ud83d\udcca Per-Bucket Correlations Found')\n",
    "    try:\n",
    "        with open(corr_path) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        bucket_corrs = np.array(data.get('bucket_corrs', []))\n",
    "        \n",
    "        if len(bucket_corrs) > 0:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            \n",
    "            # Histogram\n",
    "            ax1.hist(bucket_corrs, bins=30, alpha=0.7, color='skyblue', \n",
    "                    edgecolor='black')\n",
    "            ax1.axvline(x=bucket_corrs.mean(), color='r', linestyle='--',\n",
    "                       label=f'Mean: {bucket_corrs.mean():.3f}', linewidth=2)\n",
    "            ax1.axvline(x=0.3, color='g', linestyle='--',\n",
    "                       label='Target: 0.3', linewidth=2, alpha=0.7)\n",
    "            ax1.set_xlabel('Correlation', fontsize=12)\n",
    "            ax1.set_ylabel('Count', fontsize=12)\n",
    "            ax1.set_title('Distribution of Per-Bucket Correlations', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "            ax1.legend(fontsize=11)\n",
    "            ax1.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Box plot\n",
    "            ax2.boxplot(bucket_corrs, vert=True)\n",
    "            ax2.axhline(y=0.3, color='g', linestyle='--', \n",
    "                       label='Target: 0.3', alpha=0.7)\n",
    "            ax2.set_ylabel('Correlation', fontsize=12)\n",
    "            ax2.set_title('Per-Bucket Correlation Statistics', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "            ax2.legend(fontsize=11)\n",
    "            ax2.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Statistics\n",
    "            print('\\n\ud83d\udcc8 Per-Bucket Statistics:')\n",
    "            print(f'  Mean Correlation: {bucket_corrs.mean():.4f}')\n",
    "            print(f'  Median Correlation: {np.median(bucket_corrs):.4f}')\n",
    "            print(f'  Std Deviation: {bucket_corrs.std():.4f}')\n",
    "            print(f'  Min: {bucket_corrs.min():.4f}, Max: {bucket_corrs.max():.4f}')\n",
    "            print(f'  Buckets with Corr > 0.3: {(bucket_corrs > 0.3).sum()}/{len(bucket_corrs)}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\u274c Error: {e}')\n",
    "else:\n",
    "    print(f'\u26a0\ufe0f  Per-bucket correlations not found')\n",
    "\n",
    "print('\\n\u2713 Visualization complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cccaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Download trained model and results\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print('\u26a0\ufe0f  Not running in Google Colab - download functionality disabled')\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('=== DOWNLOAD ARTIFACTS ===\\n')\n",
    "    print('Preparing files for download...\\n')\n",
    "    \n",
    "    # Create timestamp for unique filename\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    archive_name = f'pokerbot_artifacts_{timestamp}'\n",
    "    \n",
    "    try:\n",
    "        # Check what we have\n",
    "        items_to_include = []\n",
    "        \n",
    "        if os.path.exists('models/versions/best_model.pt'):\n",
    "            items_to_include.append('Trained model (best_model.pt)')\n",
    "        \n",
    "        if os.path.exists('models/reports'):\n",
    "            report_files = os.listdir('models/reports')\n",
    "            items_to_include.append(f'Analysis reports ({len(report_files)} files)')\n",
    "        \n",
    "        if os.path.exists('scripts/config/championship.json'):\n",
    "            items_to_include.append('Championship config')\n",
    "        \n",
    "        print('\ud83d\udce6 Package contents:')\n",
    "        for item in items_to_include:\n",
    "            print(f'  \u2713 {item}')\n",
    "        \n",
    "        print(f'\\nCreating archive: {archive_name}.zip...')\n",
    "        \n",
    "        # Create temporary directory for packaging\n",
    "        os.makedirs('download_package', exist_ok=True)\n",
    "        \n",
    "        # Copy files to package directory\n",
    "        if os.path.exists('models'):\n",
    "            shutil.copytree('models', 'download_package/models', dirs_exist_ok=True)\n",
    "        \n",
    "        if os.path.exists('scripts/config'):\n",
    "            shutil.copytree('scripts/config', 'download_package/config', dirs_exist_ok=True)\n",
    "        \n",
    "        # Create README for the package\n",
    "        with open('download_package/README.txt', 'w') as f:\n",
    "            f.write('PokerBot Training Artifacts\\n')\n",
    "            f.write('='*50 + '\\n\\n')\n",
    "            f.write(f'Generated: {datetime.now()}\\n\\n')\n",
    "            f.write('Contents:\\n')\n",
    "            for item in items_to_include:\n",
    "                f.write(f'  - {item}\\n')\n",
    "            f.write('\\nUsage:\\n')\n",
    "            f.write('  1. Extract this archive\\n')\n",
    "            f.write('  2. Model file: models/versions/best_model.pt\\n')\n",
    "            f.write('  3. Reports: models/reports/\\n')\n",
    "            f.write('  4. Config: config/championship.json\\n')\n",
    "        \n",
    "        # Create ZIP archive\n",
    "        shutil.make_archive(archive_name, 'zip', 'download_package')\n",
    "        \n",
    "        # Get file size\n",
    "        file_size = os.path.getsize(f'{archive_name}.zip') / (1024 * 1024)\n",
    "        print(f'\u2713 Archive created: {archive_name}.zip ({file_size:.1f} MB)')\n",
    "        \n",
    "        # Trigger download\n",
    "        print('\\n\u2b07\ufe0f  Downloading...')\n",
    "        files.download(f'{archive_name}.zip')\n",
    "        print('\u2713 Download started!')\n",
    "        \n",
    "        # Cleanup\n",
    "        shutil.rmtree('download_package')\n",
    "        \n",
    "        print('\\n\u2705 Download complete!')\n",
    "        print('\\n\ud83d\udca1 Next steps:')\n",
    "        print('   1. Extract the ZIP file on your computer')\n",
    "        print('   2. Use the model in your poker application')\n",
    "        print('   3. Review the analysis reports for insights')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\\n\u274c Error creating download package: {e}')\n",
    "        print('\\n\ud83d\udca1 Alternative: Manually download files from the Files panel')\n",
    "else:\n",
    "    print('\\n\ud83d\udca1 To download files in local Jupyter:')\n",
    "    print('   - Navigate to the Files panel')\n",
    "    print('   - Right-click on models/ folder \u2192 Download')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_notes",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udcda Additional Resources and Tips\n",
    "\n",
    "### \ud83c\udfaf Performance Targets\n",
    "- **Correlation**: > 0.85 (excellent), 0.5-0.85 (good), < 0.5 (needs work)\n",
    "- **Relative Error**: < 5% (excellent), 5-20% (good), > 20% (needs work)\n",
    "- **Coverage**: All streets should have > 95% coverage\n",
    "\n",
    "### \ud83d\udd27 Troubleshooting Common Issues\n",
    "\n",
    "**1. Out of Memory Errors**\n",
    "- Reduce batch size: Edit `championship.json` and set `batch_size: 256`\n",
    "- Use CPU instead: Remove `--use-gpu` flag\n",
    "- Restart runtime: Runtime \u2192 Restart runtime\n",
    "\n",
    "**2. Poor Model Performance (Low Correlation)**\n",
    "- Generate more data: Increase `--samples 5000` or `--samples 10000`\n",
    "- Higher quality: Increase `--cfr-iters 2500` or `--cfr-iters 3000`\n",
    "- Train longer: Increase `--epochs 300`\n",
    "- Use adaptive sampling: See OPTIMIZATION_GUIDE.md\n",
    "\n",
    "**3. Training Takes Too Long**\n",
    "- Verify GPU is enabled (see cell 3)\n",
    "- Start with fewer samples for testing: `--samples 100 --cfr-iters 500`\n",
    "- Reduce epochs for initial testing: `--epochs 50`\n",
    "\n",
    "**4. Files Not Found Errors**\n",
    "- Ensure previous cells ran successfully\n",
    "- Check for error messages in cell outputs\n",
    "- Re-run cells in order from top to bottom\n",
    "\n",
    "### \ud83d\udcd6 Documentation\n",
    "- **QUICK_REFERENCE.md**: Quick start guide and common commands\n",
    "- **OPTIMIZATION_GUIDE.md**: Comprehensive 8-page optimization guide\n",
    "- **AUDIT_SUMMARY.md**: Summary of fixes and improvements\n",
    "- **README.md**: General project information\n",
    "\n",
    "### \ud83d\udca1 Pro Tips\n",
    "1. **Start small**: Test with 100-1000 samples before scaling up\n",
    "2. **Monitor progress**: Watch the training output for convergence\n",
    "3. **Save checkpoints**: The training script automatically saves best models\n",
    "4. **Use GPU**: 10-20x faster than CPU training\n",
    "5. **Download artifacts**: Save your trained models before closing the notebook\n",
    "\n",
    "### \ud83d\udd17 Repository\n",
    "GitHub: https://github.com/elliotttmiller/pokerbot\n",
    "\n",
    "### \ud83d\udce7 Support\n",
    "For issues or questions, please open an issue on GitHub.\n",
    "\n",
    "---\n",
    "**Happy Training! \ud83c\udfb0\ud83e\udd16**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}