{
  "num_buckets": 169,
  "bucket_count": 169,
  "bet_sizing": [1, 2],
  "hidden_sizes": [500, 500, 500, 500, 500, 500, 500],
  "activation": "prelu",
  "data_path": "src/train_samples",
  "batch_size": 1024,
  "use_gpu": true,
  "lr": 0.0005,
  "epochs": 200,
  "effective_batch_size": 4096,
  "weight_decay": 0.01,
  "warmup_epochs": 10,
  "min_lr": 1e-6,
  "huber_delta": 0.3,
  "ema_decay": 0.999,
  "early_stop_patience": 25,
  "early_stop_min_delta": 1e-6,
  "use_street_weighting": true,
  "street_weights": [0.8, 1.2, 1.4, 1.6],
  "use_torch_compile": true,
  "deterministic": false,
  "seed": 42,
  "versions_dir": "models/versions",
  "checkpoint_dir": "models/checkpoints",
  "comments": {
    "description": "Championship-level training config per DeepStack paper",
    "hidden_sizes": "7 layers Ã— 500 units per DeepStack paper Table S2",
    "batch_size": "Larger batches (1024-4096 effective) for better gradient estimates",
    "lr": "Conservative LR with warmup and cosine decay",
    "huber_delta": "Lower delta (0.3) for tighter fit in standardized space",
    "street_weights": "Emphasize later streets (flop/turn/river) for better learning",
    "epochs": "More epochs with early stopping for convergence"
  }
}
